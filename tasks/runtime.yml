---

# TODO: add validation
- name: Ensure Slurm files/directories exists
  file:
    path: "{{ item.path }}"
    owner: "{{ item.owner }}"
    group: "{{ item.group }}"
    mode: "{{ item.mode }}"
    state: "{{ item.state | default('directory') }}"
  loop: "{{ openhpc_directories }}"
  when: inventory_hostname == openhpc_slurm_control_host

- name: Read package-generated Munge key
  slurp:
    src: /etc/munge/munge.key
  register: _ohpc_munge_key_file
  run_once: true

- name: Write Munge key
  copy:
    content: "{{ openhpc_munge_key | default(_ohpc_package_munge_key) }}"
    dest: "/etc/munge/munge.key"
    owner: munge
    group: munge
    mode: 0400
  notify:
    - Restart Munge service
  vars:
    _ohpc_package_munge_key: "{{ hostvars[ansible_play_hosts | first]._ohpc_munge_key_file.content | b64decode }}"

- name: Template slurmdbd.conf
  template:
    src: slurmdbd.conf.j2
    dest: /etc/slurm/slurmdbd.conf
    mode: "0600"
    owner: slurm
    group: slurm
  notify: Restart slurmdbd service
  when: openhpc_enable.database | default(false) | bool

- name: Template slurm.conf
  template:
    src: "{{ openhpc_slurm_conf_template }}"
    dest: /etc/slurm/slurm.conf
    owner: root
    group: root
    mode: 0644
  when: openhpc_enable.control | default(false)
  notify:
    - Restart slurmctld service
  register: ohpc_slurm_conf
  # NB uses restart rather than reload as number of nodes might have changed

- name: Create gres.conf
  template:
    src: "{{ openhpc_gres_template }}"
    dest: /etc/slurm/gres.conf
    mode: "0600"
    owner: slurm
    group: slurm
  when: openhpc_enable.control | default(false)
  notify:
    - Restart slurmctld service
  register: ohpc_gres_conf
  # NB uses restart rather than reload as this is needed in some cases

- name: Template cgroup.conf
  # appears to be required even with NO cgroup plugins: https://slurm.schedmd.com/cgroups.html#cgroup_design
  template:
    src: cgroup.conf.j2
    dest: /etc/slurm/cgroup.conf
    mode: "0644" # perms/ownership based off src from ohpc package
    owner: root
    group: root
  when: openhpc_enable.control | default(false)

- name: Notify handler for slurmd restart
  debug:
    msg: "notifying handlers" # meta: noop doesn't support 'when'
  changed_when: true
  when:
    - openhpc_slurm_control_host in ansible_play_hosts
    - hostvars[openhpc_slurm_control_host].ohpc_slurm_conf.changed or hostvars[openhpc_slurm_control_host].ohpc_gres_conf.changed # noqa no-handler
  notify:
    - Restart slurmd service

- name: Set slurmctld location for configless operation
  lineinfile:
    path: /etc/sysconfig/slurmd
    line: "SLURMD_OPTIONS='--conf-server {{ openhpc_slurm_control_host_address | default(openhpc_slurm_control_host) }}'"
    regexp: "^SLURMD_OPTIONS="
    create: yes
    owner: root
    group: root
    mode: 0644
  when: openhpc_enable.batch | default(false)
  notify:
    - Restart slurmd service
  # Reloading is sufficent, but using a single handler means no bounce. Realistically this won't regularly change on a running slurmd so restarting is ok.

# Munge state could be unchanged but the service is not running.
# Handle that here.
- name: Configure Munge service
  service:
    name: munge
    enabled: "{{ openhpc_slurm_service_enabled | bool }}"
    state: "{{ 'started' if openhpc_slurm_service_started | bool else 'stopped' }}"

- name: Flush handler
  meta: flush_handlers # as then subsequent "ensure" is a no-op if slurm services bounced

- name: Ensure slurmdbd state
  service:
    name: slurmdbd
    enabled: "{{ openhpc_slurm_service_enabled | bool }}"
    state: "{{ 'started' if openhpc_slurm_service_started | bool else 'stopped' }}"
  when: openhpc_enable.database | default(false) | bool

- name: Ensure slurmctld state
  service:
    name: slurmctld
    enabled: "{{ openhpc_slurm_service_enabled | bool }}"
    state: "{{ 'started' if openhpc_slurm_service_started | bool else 'stopped' }}"
  when: openhpc_enable.control | default(false) | bool

- name: Ensure slurmd state
  service:
    name: slurmd
    enabled: "{{ openhpc_slurm_service_enabled | bool }}"
    state: "{{ 'started' if openhpc_slurm_service_started | bool else 'stopped' }}"
  when: openhpc_enable.batch | default(false)
